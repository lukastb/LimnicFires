par <- par(mfrow=c(6,3))
for(i in c(2,3,4,25:38)) {
plot(df$PC_algae2, log(df[[i]]), pch=21, col='blue', xlab="PC_algae2", ylab=names(df[i]))
nam<-paste("mod_data", i, sep="_")
assign(nam,lm(log(df[[i]])~PC_algae2, data=df)) #assign and paste paste("mod",i)
abline(get(nam))
nam_text<-paste("text", i, sep="_")
assign(nam_text, c(c(legend=paste("r² =", format(summary(get(nam))$r.squared, digits=3)),
legend=paste("p =", format(summary(get(nam))$coefficients[2,4], digits=3, scientific=FALSE))),
legend=paste("slope =", format(summary(get(nam))$coefficients[2,1], digits=3))))
legend("topleft", legend=get(nam_text), cex=1, text.font=3, bty="n")
}
x11()
par <
- par(mfrow=c(6,3))
x11()
par <- par(mfrow=c(6,3))
for(i in c(2,3,4,25:38)) {
plot(df$PC_algae2, df[[i]], pch=21, col='blue', xlab="PC_algae2", ylab=names(df[i]), na.a)
nam<-paste("mod_data", i, sep="_")
assign(nam,lm(df[[i]]~PC_algae2, data=df)) #assign and paste paste("mod",i)
abline(get(nam))
nam_text<-paste("text", i, sep="_")
assign(nam_text, c(c(legend=paste("r² =", format(summary(get(nam))$r.squared, digits=3)),
legend=paste("p =", format(summary(get(nam))$coefficients[2,4], digits=3, scientific=FALSE))),
legend=paste("slope =", format(summary(get(nam))$coefficients[2,1], digits=3))))
legend("topleft", legend=get(nam_text), cex=1, text.font=3, bty="n")
}
for(i in c(2,3,4,25:38)) {
plot(df$PC_algae2, df[[i]], pch=21, col='blue', xlab="PC_algae2", ylab=names(df[i]))
nam<-paste("mod_data", i, sep="_")
assign(nam,lm(df[[i]]~PC_algae2, data=df)) #assign and paste paste("mod",i)
abline(get(nam))
nam_text<-paste("text", i, sep="_")
assign(nam_text, c(c(legend=paste("r² =", format(summary(get(nam))$r.squared, digits=3)),
legend=paste("p =", format(summary(get(nam))$coefficients[2,4], digits=3, scientific=FALSE))),
legend=paste("slope =", format(summary(get(nam))$coefficients[2,1], digits=3))))
legend("topleft", legend=get(nam_text), cex=1, text.font=3, bty="n")
}
# PC_CC with PC_algae
plot(df$PC_algae2, df$PC_CC1)
mod <- lm(df$PC_CC1~df$PC_algae2)
abline(mod)
summary(mod)
plot(df$PC_algae1, df$PC_CC1)
mod <- lm(df$PC_CC1~df$PC_algae1)
abline(mod)
summary(mod)
plot(df$PC_algae2, df$PC_CC2)
mod <- lm(df$PC_CC2~df$PC_algae2)
abline(mod)
summary(mod)
plot(df$PC_algae2, df$H)
mod <- lm(df$H~df$PC_algae2)
abline(mod)
summary(mod)
max(df$catchment_area)
min(df$catchment_area)
library(vegan)
library(packfor)
library(shape)
geo<-read.csv("C:/Users/thuile/PhD/Albania 04.2018/General/geology_VJ.csv", header=TRUE, check.names = FALSE, sep=";")
rownames(geo)<-geo$site
geo<-geo[,-1]
# land<-read.csv("C:/Users/thuile/PhD/Albania 04.2018/General/landuse_VJ.csv", header=TRUE, sep=";")
# rownames(land)<-land$site
# land<-land[,-1]
# # PCA on landuse
# #zland <- scale(land,center=TRUE,scale=TRUE) #maybe without scaling
# pca<-prcomp(land)
#
# summary(pca)
#
# pca.pct<-100*round(summary(pca)$importance[2,],3)#show proportion of variance of the PC's
# barplot(pca.pct)#keep PC 1 to 4!
#
# #PCA plot
# biplot(pca,scale=0,xlab="PC1   78%",ylab="PC2   15%")
# # PC1 reflects and urbanisation gradient
# # PC2 reflects different typ of vegations (Veg=natural vegetation without forest; BAR=bare and sparsely vegetated area)
# # -> No change in meaning of PCA if land is standardized or not
#
# #extract scores
# PC_LU<-pca$x
# a<-paste("PC_LU",1:6,sep="")
# colnames(PC_LU)<-a
# #write.table(PC_LU,"C:/Users/thuile/PhD/Albania 04.2018/General/PC_LU.txt", sep=",")
# PCA on geology
pca<-prcomp(geo)
summary(pca)
pca.pct<-100*round(summary(pca)$importance[2,],3) #show proportion of variance of the PC's
barplot(pca.pct)#keep PC 1 to 4!
#PCA plot
biplot(pca,scale=0,xlab="PC1   41%",ylab="PC2   24%")
#extract scores
PC_G<-pca$x
a<-paste("PC_G",1:13,sep="")
colnames(PC_G)<-a
loadings<-pca$rotation
#write.table(PC_G,"C:/Users/thuile/PhD/Albania 04.2018/General/PC_G.txt", sep=",")
plot(PC_G[,1],PC_G[,2], xlab="GEO PC1   41%", ylab="GEO PC2   24%", pch=21, bg="gray70", cex=2, xlim=c(-80,60), ylim=c(-80,60))
text(PC_G[,1],PC_G[,2], rownames(PC_G), cex=1)
arrows<-loadings*80 # extension factor; can be any number to visualize the plot better; BUT watch out-> plotcircle must have the same number!
Arrows(x0=0,y0=0,x1=arrows[,1],y1=arrows[,2],col="black", lwd=1.5, code=2)
text(x=arrows[,1]*1.2, y=arrows[,2]*1.2, labels=rownames(arrows), cex=1, col="black")
plotcircle(r=80*sqrt(2/ncol(PC_G)),lcol="black", lwd=1) # circle of equilibrium contribution (equal contribution to all PCA-dimensions)
asv_bent <- readRDS("C:/Users/thuile/PhD/DNA/DNA_processed/PrimerClipped/Mara/maxEE3_5 truncLen230_190/benthic/seqtab_bact_only.rds")
# set colnames
headers <- paste("ASV",seq(1:ncol(asv_bent)),sep="")
colnames(asv_bent)<-headers
asv_bent[1:10, 1:10]
asv_mat[1:10, 1:10]
# check library sizes
lib_sizes <- as.data.frame(rowSums(asv_bent))
lib_sizes$site <- rownames(asv_bent)
# remove site 22b (22 has more reads) and site 7 and site 21
rownames(asv_bent)
asv_bent <- asv_bent[-c(which(rownames(asv_bent)=="341F-785R-P3-Kb21"), which(rownames(asv_bent)=="341F-785R-P4-Kb7"), which(rownames(asv_bent)=="341F-785R-P3-Kb22-b")),]
rownames(asv_bent)
# set rownames
rn_b <- substr(rownames(asv_bent), 16, 17)
rn_b[length(rn_b)] <- "63+" #the last site of the asv_bent is the 63+ -> so I rename it to not have 2 63's in there
rownames(asv_bent) #check rownames
rownames(asv_bent) <- rn_b
rownames(asv_bent) #check again to see if everything matches
# lib size plot
lib_sizes <- as.data.frame(rowSums(asv_bent))
lib_sizes$site <- rownames(asv_bent)
lib_sizes <- lib_sizes[order(lib_sizes$`rowSums(asv_bent)`),]
barplot(lib_sizes$`rowSums(asv_bent)`, names.arg=lib_sizes$site, las=2)
# just to check if RDS is better than table and csv -> IT IS!
saveRDS(asv_bent,"C:/Users/thuile/PhD/Kenya_2018/Biofilm community/asv_bent_raw.rds")
asv_bent2 <- readRDS("C:/Users/thuile/PhD/Kenya_2018/Biofilm community/asv_bent_raw.rds")
asv_bent[1:10, 1:10]
asv_bent2[1:10, 1:10]
ncol(asv_bent); nrow(asv_bent)
ncol(asv_bent2); nrow(asv_bent2)
#####read in and re-organize taxa table#####
taxa_bent <- read.csv("C:/Users/thuile/PhD/DNA/DNA_processed/PrimerClipped/Mara/maxEE3_5 truncLen230_190/benthic/taxa_bact_only.csv")
View(taxa_bent)
rowSums(asv_bent)
rownames(taxmat)<-headers
rownames(taxa_bent)<-headers
taxa_bent <- taxa_bent[,-c(1,2)]
write.table(taxa_bent,"taxa_bent.txt", sep=",")
getwd()
write.table(taxa_bent,"C:/Users/thuile/PhD/Kenya_2018/Biofilm community/taxa_bent.txt", sep=",")
#write.table(taxa_bent,"C:/Users/thuile/PhD/Kenya_2018/Biofilm community/taxa_bent.txt", sep=",")
taxa_bent2 <- read.table(taxa_bent,"C:/Users/thuile/PhD/Kenya_2018/Biofilm community/taxa_bent.txt", sep=",")
#write.table(taxa_bent,"C:/Users/thuile/PhD/Kenya_2018/Biofilm community/taxa_bent.txt", sep=",")
taxa_bent2 <- read.table("C:/Users/thuile/PhD/Kenya_2018/Biofilm community/taxa_bent.txt", sep=",")
# write.table(taxa_bent,"C:/Users/thuile/PhD/Kenya_2018/Biofilm community/taxa_bent.txt", sep=",")
# taxa_bent2 <- read.table("C:/Users/thuile/PhD/Kenya_2018/Biofilm community/taxa_bent.txt", sep=",")
identical(taxa_bent, taxa_bent2)
#=============Planktonic========================
#####read in and re-organize data#####
asv_plank <- readRDS("C:/Users/thuile/PhD/DNA/DNA_processed/PrimerClipped/Mara/maxEE3_5 truncLen230_190/planktonic/seqtab_bact_only.rds")
ncol(asv_plank)
# set colnames
headers <- paste("ASV",seq(1:ncol(asv_plank)),sep="")
colnames(asv_plank) <- headers
asv_plank[1:10, 1:10]
# check library sizes
lib_sizes <- as.data.frame(rowSums(asv_plank))
lib_sizes$site <- rownames(asv_plank)
View(lib_sizes)
asv_bent <- readRDS("C:/Users/thuile/PhD/DNA/DNA_processed/PrimerClipped/Mara/maxEE3_5 truncLen230_190/benthic/seqtab_bact_only.rds")
# set colnames
headers <- paste("ASV",seq(1:ncol(asv_bent)),sep="")
colnames(asv_bent)<-headers
asv_bent[1:10, 1:10]
# check library sizes
lib_sizes_b <- as.data.frame(rowSums(asv_bent))
lib_sizes_b$site <- rownames(asv_bent)
# remove site 22b (22 has more reads) and site 7 and site 21
rownames(asv_bent)
asv_bent <- asv_bent[-c(which(rownames(asv_bent)=="341F-785R-P3-Kb21"), which(rownames(asv_bent)=="341F-785R-P4-Kb7"), which(rownames(asv_bent)=="341F-785R-P3-Kb22-b")),]
rownames(asv_bent)
# set rownames
rn_b <- substr(rownames(asv_bent), 16, 17)
rn_b[length(rn_b)] <- "63+" #the last site of the asv_bent is the 63+ -> so I rename it to not have 2 63's in there
rownames(asv_bent) #check rownames
rownames(asv_bent) <- rn_b
rownames(asv_bent) #check again to see if everything matches
# lib size plot
lib_sizes_b <- as.data.frame(rowSums(asv_bent))
lib_sizes_b$site <- rownames(asv_bent)
lib_sizes_b <- lib_sizes_b[order(lib_sizes_b$`rowSums(asv_bent)`),]
barplot(lib_sizes_b$`rowSums(asv_bent)`, names.arg=lib_sizes_b$site, las=2)
# just to check if RDS is better than table and csv -> IT IS!
saveRDS(asv_bent,"C:/Users/thuile/PhD/Kenya_2018/Biofilm community/asv_bent_raw.rds")
asv_bent2 <- readRDS("C:/Users/thuile/PhD/Kenya_2018/Biofilm community/asv_bent_raw.rds")
asv_bent[1:10, 1:10]
asv_bent2[1:10, 1:10]
ncol(asv_bent); nrow(asv_bent)
ncol(asv_bent2); nrow(asv_bent2)
asv_plank <- readRDS("C:/Users/thuile/PhD/DNA/DNA_processed/PrimerClipped/Mara/maxEE3_5 truncLen230_190/planktonic/seqtab_bact_only.rds")
# set colnames
headers <- paste("ASV",seq(1:ncol(asv_plank)),sep="")
colnames(asv_plank) <- headers
asv_plank[1:10, 1:10]
# check library sizes
lib_sizes_p <- as.data.frame(rowSums(asv_plank))
lib_sizes_p$site <- rownames(asv_plank)
View(lib_sizes_p)
# set rownames
rn_p <- substr(rownames(asv_plank), 16, 17)
rownames(asv_plank)
# set rownames
rn_p <- substr(rownames(asv_plank), 17, 18)
rownames(asv_plank) #check rownames
rownames(asv_plank) <- rn_p
rownames(asv_plank) #check again to see if everything matches
# lib size plot
lib_sizes_p <- as.data.frame(rowSums(asv_plank))
lib_sizes_p$site <- rownames(asv_plank)
lib_sizes_p <- lib_sizes_p[order(lib_sizes_p$`rowSums(asv_plank)`),]
barplot(lib_sizes_p$`rowSums(asv_plank)`, names.arg=lib_sizes_p$site, las=2)
# just to check if RDS is better than table and csv -> IT IS!
saveRDS(asv_plank,"C:/Users/thuile/PhD/Kenya_2018/Biofilm community/asv_plank_raw.rds")
asv_plank2 <- readRDS("C:/Users/thuile/PhD/Kenya_2018/Biofilm community/asv_plank_raw.rds")
asv_plank[1:10, 1:10]
asv_plank2[1:10, 1:10]
ncol(asv_plank); nrow(asv_plank)
ncol(asv_plank2); nrow(asv_plank2)
ncol(asv_bent); nrow(asv_bent)
ncol(asv_bent2); nrow(asv_bent2)
#####rarefy#####
library(vegan)
asv_b_raw<-readRDS("C:/Users/thuile/PhD/Kenya_2018/Biofilm community/asv_bent_raw.rds")
lib_sizes_b<-as.data.frame(rowSums(asv_b_raw))#14 sites are below 400
which(lib_sizes<1000)
which(lib_sizes_b<1000)
asv_b_freq <- specnumber(asv_b_raw, MARGIN = 2)
barplot(sort(asv_b_freq,decreasing=T),xlab="Sites",ylab="Number of ASV's",cex.names = 0.8)
R_bent <- specnumber(asv_b_raw, MARGIN = 1)
barplot(sort(asv_b_freq, decreasing=T), xlab="Sites", ylab="Frequency of ASV's", cex.names = 0.8)
asv_b_raw$ASV1
asv_b_raw[,1]
R_bent <- specnumber(asv_b_raw, MARGIN = 1)
barplot(sort(R_bent, decreasing=T), xlab="Sites", ylab="Number of ASV's", cex.names = 0.8)
View(lib_sizes_b)
lib_sizes_b$site <- rownames(asv_b_raw)
# plot lib sizes
lib_sizes_b <- as.data.frame(rowSums(asv_b_raw))
lib_sizes_b$site <- rownames(asv_b_raw)
lib_sizes_b <- lib_sizes_b[order(lib_sizes_b$`rowSums(asv_b_raw)`),]
barplot(lib_sizes_b$`rowSums(asv_b_raw)`, names.arg=lib_sizes_b$site, las=2)
raremax <- 1000#min(rowSums(asv_t))
Srare <- rarefy(asv_b_raw, raremax)
plot(S, Srare, xlab = "Observed No. of Species", ylab = "Rarefied No. of Species")
library(vegan)
asv_b_raw<-readRDS("C:/Users/thuile/PhD/Kenya_2018/Biofilm community/asv_bent_raw.rds")
# plot lib sizes
lib_sizes_b <- as.data.frame(rowSums(asv_b_raw))
lib_sizes_b$site <- rownames(asv_b_raw)
lib_sizes_b <- lib_sizes_b[order(lib_sizes_b$`rowSums(asv_b_raw)`),]
barplot(lib_sizes_b$`rowSums(asv_b_raw)`, names.arg=lib_sizes_b$site, las=2)
abline(h=1000)
abline(v=1000)
abline(v=1000, col="black")
abline(v=1500, col="black")
abline(v=3500, col="black")
abline(v=3500)
barplot(lib_sizes_b$`rowSums(asv_b_raw)`, names.arg=lib_sizes_b$site, las=2)
abline(v=3500)
abline(h=1000, col="black")
abline(h=1500, col="blue")
abline(h=1750, col="red")
abline(h=1800, col="red")
barplot(lib_sizes_b$`rowSums(asv_b_raw)`, names.arg=lib_sizes_b$site, las=2)
abline(h=1000, col="black")
abline(h=1500, col="blue")
abline(h=1800, col="red")
barplot(lib_sizes_b$`rowSums(asv_b_raw)`, names.arg=lib_sizes_b$site, las=2)
abline(h=817, col="black") #lib size of site 62
abline(h=1378, col="blue") #lib size of site 44
abline(h=1785, col="red") #lib size of site 12
t1 <- which(lib_sizes_b<817)
lib_sizes_b$site[which(lib_sizes_b<817)]
t1 <- lib_sizes_b$site[which(lib_sizes_b<817)]
t1 <- t1[!is.na(t1)]
t1 <- lib_sizes_b$site[which(lib_sizes_b<817)]
t1 <- t1[!is.na(t1)]
t2 <- lib_sizes_b$site[which(lib_sizes_b<1378)]; t2 <- t2[!is.na(t2)]
t3 <- lib_sizes_b$site[which(lib_sizes_b<1785)]; t3 <- t3[!is.na(t3)]
t1 <- lib_sizes_b$site[which(lib_sizes_b<=817)]; t1 <- t1[!is.na(t1)]
t2 <- lib_sizes_b$site[which(lib_sizes_b<=1378)]; t2 <- t2[!is.na(t2)]
t3 <- lib_sizes_b$site[which(lib_sizes_b<=1785)]; t3 <- t3[!is.na(t3)]
c(t1)
t1
# make df's according to different raremax
asv_t1 <- asv_b_raw[!rownames(asv_b_raw) %in% c(t1), ]#remove sites small lib-sizes
asv_t2 <- asv_b_raw[!rownames(asv_b_raw) %in% c(t2), ]#remove sites small lib-sizes
asv_t3 <- asv_b_raw[!rownames(asv_b_raw) %in% c(t3), ]#remove sites small lib-sizes
nrow(asv_t1); nrow(asv_t2); nrow(asv_t3)
# make rarefy plots for different settings
raremax1 <- min(rowSums(asv_t1))
raremax2 <- min(rowSums(asv_t2))
raremax3 <- min(rowSums(asv_t3))
Srare <- rarefy(asv_t1, raremax1)
Srare <- rarefy(asv_t2, raremax2)
Srare <- rarefy(asv_t3, raremax3)
plot(S, Srare, xlab = "Observed No. of Species", ylab = "Rarefied No. of Species")
S1 <- specnumber(asv_t1)
S2 <- specnumber(asv_t2)
S3 <- specnumber(asv_t3)
plot(S1, Srare1, xlab = "Observed No. of Species", ylab = "Rarefied No. of Species")
raremax1 <- min(rowSums(asv_t1))
raremax2 <- min(rowSums(asv_t2))
raremax3 <- min(rowSums(asv_t3))
Srare1 <- rarefy(asv_t1, raremax1)
Srare2 <- rarefy(asv_t2, raremax2)
Srare3 <- rarefy(asv_t3, raremax3)
S1 <- specnumber(asv_t1)
S2 <- specnumber(asv_t2)
S3 <- specnumber(asv_t3)
plot(S1, Srare1, xlab = "Observed No. of Species", ylab = "Rarefied No. of Species")
abline(0, 1)
rarecurve(asv_t, step = 25, sample = raremax, col = "blue", cex = 0.6,label=TRUE) #vertical black line is equal to the value of raremax
rarecurve(asv_t1, step = 25, sample = raremax1, col = "blue", cex = 0.6,label=TRUE) #vertical black line is equal to the value of raremax
plot(S2, Srare2, xlab = "Observed No. of Species", ylab = "Rarefied No. of Species")
abline(0, 1)
plot(S1, Srare1, xlab = "Observed No. of Species", ylab = "Rarefied No. of Species")
abline(0, 1)
plot(S2, Srare2, xlab = "Observed No. of Species", ylab = "Rarefied No. of Species")
abline(0, 1)
plot(S1, Srare1, xlab = "Observed No. of Species", ylab = "Rarefied No. of Species", col="green")
abline(0, 1)
plot(S2, Srare2, xlab = "Observed No. of Species", ylab = "Rarefied No. of Species", col="blue")
abline(0, 1)
plot(S3, Srare3, xlab = "Observed No. of Species", ylab = "Rarefied No. of Species", col="red")
abline(0, 1)
rarecurve(asv_t1, step = 25, sample = raremax1, col = "green", cex = 0.6,label=TRUE) #vertical black line is equal to the value of raremax
rarecurve(asv_t2, step = 25, sample = raremax2, col = "blue", cex = 0.6,label=TRUE) #vertical black line is equal to the value of raremax
rarecurve(asv_t3, step = 25, sample = raremax3, col = "red", cex = 0.6,label=TRUE) #vertical black line is equal to the value of raremax
# rarefy
asv_rr1<-rrarefy(asv_t1,raremax1)
cs1<-colSums(asv_rr1)
is.element("0", cs1)
sum(cs1==0)
nodata1<-which(cs1==0)#columns that contain colSums of zero
length(which(cs1==0))#again 115, so it is correct
library(phyloseq)
asv_rr2<-rrarefy(asv_t2,raremax2)
cs2<-colSums(asv_rr2)
is.element("0", cs2)
sum(cs2==0)
nodata2<-which(cs2==0)#columns that contain colSums of zero
length(which(cs2==0))#again the same number as the line above, so it is correct
asv_rr2<-asv_rr2[,-nodata2]#create a new df without the columns that summed up to 0
asv_rr3<-rrarefy(asv_t3,raremax3)
cs3<-colSums(asv_rr3)
is.element("0", cs3)
sum(cs3==0)
nodata3<-which(cs3==0)#columns that contain colSums of zero
length(which(cs3==0))#again the same number as the line above, so it is correct
asv_rr3<-asv_rr3[,-nodata3]#create a new df without the columns that summed up to 0
asv_rr1<-rrarefy(asv_t1,raremax1)
cs1<-colSums(asv_rr1)
is.element("0", cs1)
sum(cs1==0)
nodata1<-which(cs1==0)#columns that contain colSums of zero
length(which(cs1==0))#again the same number as the line above, so it is correct
asv_rr1<-asv_rr1[,-nodata1]#create a new df without the columns that summed up to 0
asv_rr2<-rrarefy(asv_t2,raremax2)
cs2<-colSums(asv_rr2)
is.element("0", cs2)
sum(cs2==0)
nodata2<-which(cs2==0)#columns that contain colSums of zero
length(which(cs2==0))#again the same number as the line above, so it is correct
asv_rr2<-asv_rr2[,-nodata2]#create a new df without the columns that summed up to 0
asv_rr3<-rrarefy(asv_t3,raremax3)
cs3<-colSums(asv_rr3)
is.element("0", cs3)
sum(cs3==0)
nodata3<-which(cs3==0)#columns that contain colSums of zero
length(which(cs3==0))#again the same number as the line above, so it is correct
asv_rr3<-asv_rr3[,-nodata3]#create a new df without the columns that summed up to 0
asv_rr3<-rrarefy(asv_t3,raremax3)
cs3<-colSums(asv_rr3)
is.element("0", cs3)
sum(cs3==0)
nodata3<-which(cs3==0)#columns that contain colSums of zero
length(which(cs3==0))#again the same number as the line above, so it is correct
asv_rr3<-asv_rr3[,-nodata3]#create a new df without the columns that summed up to 0
nrow(asv_t1); nrow(asv_t2); nrow(asv_t3)
# prepare asv tables for nMDS
length(rare_species_raw<-which(specnumber(asv_b_raw,MARGIN=2)<3)) #490 species which occure in less than 3 sites
ncol(asv_b_raw)
asv_raw<-asv_b_raw[,-rare_species_raw] #use this line to exclude rara species
ncol(asv_raw)
library(data.table)
library(tidyr)
library(rstan)
library(bayesplot)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
setwd("C:/Users/thuile/PhD/GitHub/LimnicFires")
dom_dat = fread("data/DOM.txt")
doc_dat = fread("data/DOC_molten.txt")
## drop unneeded row numbers
dom_dat[["V1"]] = NULL
doc_dat[["V1"]] = NULL
# flume names should be unique
doc_dat[, flume := factor(paste(flume, treat, sep="_"))]
doc_wide = as(pivot_wider(doc_dat, id_cols=c("flume", "time"), names_from="time"), "data.table")
stan_dat = list(
n_flumes = nrow(doc_wide),
n_time = ncol(doc_wide) - 1,
times = as.integer(colnames(doc_wide)[-1]),
treatment = ifelse(grepl("T", doc_wide$flume), 1, 0),
y = as.matrix(doc_wide[,-1])
)
fit = stan("code/ar1_simple.stan", data = stan_dat, iter=5000)
mcmc_dens_overlay(as.array(fit))
# compare with a latent variable model, which is a bit more correct
# some fitting complications required a bit of tuning, hence diagnostic plots and changing
# adapt_delta
fit_gp = stan("code/ar1_gp.stan", data = stan_dat, iter=10000, control=list(adapt_delta = 0.95))
parnames = c("rho", "a_gp", "sigma", "alpha", "beta")
samps = as.array(fit_gp, pars = parnames)
mcmc_trace(samps)
mcmc_dens_overlay(samps)
s1 = rstan::extract(fit, c("alpha", "beta"))
s2 = rstan::extract(fit_gp, c("alpha", "beta"))
ci_disp = function(x, digits = 3, lower = 0.05, upper = 0.95) {
paste0(round(median(x), digits), " (",
round(quantile(x, lower), digits), ", ",
round(quantile(x, upper), digits), ")"
)
}
matrix(c(sapply(s1, ci_disp, digits = 3), sapply(s2, ci_disp, digits = 3)), nrow = 2,
dimnames = list(c("alpha", "beta"), c("AR1", "GP")))
View(doc_wide)
barplot(doc_dat$value)
barplot(frequency(doc_dat$value))
# check distribution of DOC
hist(doc_dat$value, freq = FALSE)
lines(density(doc_dat$value))
#
hist(log(doc_dat$value), freq = FALSE)
lines(density(log(doc_dat$value)))
View(doc_dat)
plot(as.character(doc_dat$time[doc_dat$treat=="C"]), doc_dat$value[doc_dat$treat=="C"], type="p", ylim=c(2.5,7), pch=21, bg="grey80", cex=2, xlab="Time (h)", ylab= "DOC (mg/l)", cex.lab=2, cex.axis=2)
points(as.character(doc_dat$time[doc_dat$treat=="T"]), doc_dat$value[doc_dat$treat=="T"], type="p", ylim=c(2,7), pch=21, bg="grey20", cex=2)
mod_contr <- lm(doc_dat$value[doc_dat$treat=="C"] ~ as.numeric(as.character(doc_dat$time[doc_dat$treat=="C"])))
abline(mod_contr, col="grey80", lwd=2)
mod_treat <- lm(doc_dat$value[doc_dat$treat=="T"] ~ as.numeric(as.character(doc_dat$time[doc_dat$treat=="T"])))
abline(mod_treat, col="grey20", lwd=2)
par(mar=c(5,5,2,2))
plot(as.character(doc_dat$time[doc_dat$treat=="C"]), doc_dat$value[doc_dat$treat=="C"], type="p", ylim=c(2.5,7), pch=21, bg="grey80", cex=2, xlab="Time (h)", ylab= "DOC (mg/l)", cex.lab=2, cex.axis=2)
points(as.character(doc_dat$time[doc_dat$treat=="T"]), doc_dat$value[doc_dat$treat=="T"], type="p", ylim=c(2,7), pch=21, bg="grey20", cex=2)
mod_contr <- lm(doc_dat$value[doc_dat$treat=="C"] ~ as.numeric(as.character(doc_dat$time[doc_dat$treat=="C"])))
abline(mod_contr, col="grey80", lwd=2)
mod_treat <- lm(doc_dat$value[doc_dat$treat=="T"] ~ as.numeric(as.character(doc_dat$time[doc_dat$treat=="T"])))
abline(mod_treat, col="grey20", lwd=2)
legend("topleft", legend=c("Treatment", "Control"), pch=c(21,21), pt.bg=c("grey20", "grey80"), cex=2, y.intersp = 0.75, bty="n")
plot(as.character(doc_dat$time[doc_dat$treat=="C"]), doc_dat$value[doc_dat$treat=="C"], type="p", ylim=c(2.5,7), pch=21, bg="grey80", cex=2, xlab="Time (h)", ylab= "DOC (mg/l)", cex.lab=2, cex.axis=2)
points(as.character(doc_dat$time[doc_dat$treat=="T"]), doc_dat$value[doc_dat$treat=="T"], type="p", ylim=c(2,7), pch=21, bg="grey20", cex=2)
doc_dat$value[doc_dat$treat=="C"]
as.numeric(as.character(doc_dat$time[doc_dat$treat=="C"]))
##    2. Investigate likelihood and distribution
# check distribution of DOC -> right skewed
hist(doc_dat$value, freq = FALSE)
lines(density(doc_dat$value))
#
hist(log(doc_dat$value), freq = FALSE)
lines(density(log(doc_dat$value)))
##    3. compare fits with GLM
mod <- glm(value ~ time, family = gaussian, data = doc_dat)
summary(mod)
matrix(c(sapply(s1, ci_disp, digits = 3), sapply(s2, ci_disp, digits = 3)), nrow = 2,
dimnames = list(c("alpha", "beta"), c("AR1", "GP")))
plot(as.character(doc_dat$time[doc_dat$treat=="C"]), doc_dat$value[doc_dat$treat=="C"], type="p", ylim=c(2.5,7), pch=21, bg="grey80", cex=2, xlab="Time (h)", ylab= "DOC (mg/l)", cex.lab=2, cex.axis=2)
points(as.character(doc_dat$time[doc_dat$treat=="T"]), doc_dat$value[doc_dat$treat=="T"], type="p", ylim=c(2,7), pch=21, bg="grey20", cex=2)
##    3. compare fits with GLM
mod <- glm(value ~ time, family = gaussian, data = doc_dat)
summary(mod)
x_line = data.frame(k=seq(min(doc_dat$value), max(doc_dat$value), length.out = 1000))
y_line = predict(mod, newdata = x_line, type = "link", se.fit = TRUE)
x_line = data.frame(k=seq(min(doc_dat$value), max(doc_dat$value), length.out = 1000))
View(x_line)
y_line = predict(mod, newdata = x_line, type = "link", se.fit = TRUE)
View(x_line)
x_line = data.frame(doc=seq(min(doc_dat$value), max(doc_dat$value), length.out = 1000))
y_line = predict(mod, newdata = x_line, type = "link", se.fit = TRUE)
x_line = data.frame(value=seq(min(doc_dat$value), max(doc_dat$value), length.out = 1000))
y_line = predict(mod, newdata = x_line, type = "link", se.fit = TRUE)
x_line = matrix(value=seq(min(doc_dat$value), max(doc_dat$value), length.out = 1000))
x_line = data.frame(value=seq(min(doc_dat$value), max(doc_dat$value), length.out = 1000))
y_line = predict(mod, newdata = x_line, se.fit = TRUE)
y_line = predict(mod, newdata = as.matrix(x_line), se.fit = TRUE)
abline(mod)
x_line = data.frame(value=seq(min(doc_dat$time), max(doc_dat$time), length.out = 1000))
y_line = predict(mod, newdata = x_line, type = "link", se.fit = TRUE)
min(doc_dat$time)
max(doc_dat$time)
View(x_line)
summary(mod)
x_line = data.frame(time=seq(min(doc_dat$time), max(doc_dat$time), length.out = 1000))
y_line = predict(mod, newdata = x_line, type = "link", se.fit = TRUE)
polygon(c(x_line$time, rev(x_line$time)),(c(y_line$fit + y_line$se.fit, rev(y_line$fit - y_line$se.fit))), border=NA, col="#66666666")
lines(x_line$time, y_line$fit)
plot(as.character(doc_dat$time[doc_dat$treat=="C"]), doc_dat$value[doc_dat$treat=="C"], type="p", ylim=c(2.5,7), pch=21, bg="grey80", cex=2, xlab="Time (h)", ylab= "DOC (mg/l)", cex.lab=2, cex.axis=2)
points(as.character(doc_dat$time[doc_dat$treat=="T"]), doc_dat$value[doc_dat$treat=="T"], type="p", ylim=c(2,7), pch=21, bg="grey20", cex=2)
mod <- glm(value ~ time, family = gaussian, data = doc_dat)
summary(mod)
x_line = data.frame(time=seq(min(doc_dat$time), max(doc_dat$time), length.out = 1000))
y_line = predict(mod, newdata = x_line, type = "link", se.fit = TRUE)
polygon(c(x_line$time, rev(x_line$time)),(c(y_line$fit + y_line$se.fit, rev(y_line$fit - y_line$se.fit))), border=NA, col="#66666666")
lines(x_line$time, y_line$fit)
